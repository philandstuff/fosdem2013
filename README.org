#+TITLE:FOSDEM 2013

* Nathan Harvey, Learning to Automate
https://speakerdeck.com/nathenharvey/learning-to-automate
** evolving towards automation:
   1. just make it work
   2. then write notes and store in server.txt
   3. then publish those notes in wiki
   4. then convert notes to scripts
   5. then put scripts into source control
      - and not the =.bak= or =.<date>= kind
** new experiences when automating:
   - new terminology
   - new programming languages
   - new way of thinking about infrastructure
     - livestock, not pets
** challenges for educators
   - snowflakes -- everyone's infrastructure is different and under
     different constraints
   - deployment variation
     - loads and loads of options here
     - OS packages
     - .jars and .wars
     - capistrano
     - not to mention options for injecting environment-specific config
   - massively varying background of practitioners
     - sysadmins vs devs, broadly
     - but variation within and outside of these categories
   - rate of innovation of field
** Three archetypal learners
   - senior sysadmin
     - understands:
       - domain
       - tooling
     - doesn't understand
       - high-level abstraction
       - testing and TDD
     - needs examples and peer-based learning
   - "Trust fund" kid
     - has inherited an existing chef/puppet/cfengine codebase but
       doesn't understand it
     - value of automation lowered by lack of understanding
     - needs mentoring
   - the dev migrating to operations
     - understands:
       - abstraction
       - testing
     - doesn't understand:
       - OS-level concepts and techniques
     - willing to dig into ruby source code to understand things
     - needs domain expertise
   - Pattern here: massive variation in:
     - motivation
     - existing skills
** How can we help?
   - Community
     - conferences, usergroups, etc
   - support and mentoring for those around you
** finally: if you're using vagrant, use veewee!
* Brian Berry, Using Ruby testing frameworks for sanity
  - slides at https://speakerdeck.com/bryanwb/dont-shrug-integration-testing-for-infrastructure-with-ruby-frameworks
  - code at https://github.com/bryanwb/tk-demo
** standard shape:
   - appservers, loadbalancers, database nodes, database caches
** big data deathstar is coming
   - hadoop, zookeeper, apache mesos
** testing; two kinds
   - white box
   - black box
** you should use ruby
   - lightweight
   - libraries
   - rspec
   - easy to mock services (sinatra) (what does this mean?)
   - vagrant!
** minitest chef handler
** test kitchen
** Jamie CI aka Test-Kitchen 1.0
   - simple job:
     - define machines
     - provide virtualization backend
       - eg vagrant
   - define VMs using a single yaml file
   - supports librarian-chef and berkshelf
   - tests VMs concurrently
** BATS - Bash Automated Testing System
   - testing using bash, sort of
** "Smoke" tests
   - Don't need to test multiple OS versions
   - How to DRY up common driver configs?
   - Where to put IP config?
** logging
   - test-kitchen creates one log per VM
** wiring
   - hardcoding IP address in Vagrantfile?
   - assigning IP using Chef Server or Puppetmaster?
   - Presenting: Chef-Workflow
** Brian's super-cool Systems Management model
   - Finite State Machine (zookeeper) [wtf?]
   - orchestration (rake)
   - discovery (puppetdb/chef server)
   - provisioning (puppet/chef/cfengine)
   - machines (test-kitchen)
   - virt. drivers (vagrant)
** More awesome ruby libraries
   - Faraday
   - Sinatra
   - Rspec-dns
   - ruby-dns
** Summary
   - You can do a lot of basic integration testing _right now_ with
     vagrant + rake
   - concurrent VM task execution important (though controversial)
   - Need DSL for integration tests
   - Test-Kitchen alpha but exciting
   - There is gold in Chef-Workflow
   - We need public CI for chef cookbooks etc
** zookeeper
   - useful for maintaining dynamic state
   - master/slave
   - group membership
   - when I add an appserver, I don't want to wait for the next puppet
     run to have it added to the lb pool
     - zookeeper "basically" a key-value store with events and notifications
     - load balancer can listen for new appservers
** TODO Aside: Brians emacs for ruby:
   - Paredit?!
   - RBlock?
   - Ruby mode
* Pat Debois, spontaneous veewee talk
** vagrant
   - creates and destroys VMs very quickly
   - all starts from a base box
** veewee
   - https://github.com/jedi4ever/veewee
   - takes pain out of building vagrant boxes
     - also KVM, vmware
   - interact with those vms (up/destroy/halt/ssh)
   - export them: OVA for fusion, IMG for KVM, ovf for virtualbox
* Maciej Pasternacki, A Continuous Packaging Pipeline
  - @mpasternacki
  - https://speakerdeck.com/mpasternacki/a-continuous-packaging-pipeline
  - http://bit.ly/cont-pkg < talk notes
** Web infrastructure problems
   - nginx is too old
   - I need node.js
     - compiling on the server is /wrong/
   - I need foo.jar on all appservers
     - a Java VM would help using it
** Package all the things!
   - http://xallthey.com/package.all.the.things
   - barriers:
     - debian policy manual
   - Goals:
     - 
       1. git push
       2. ...
       3. profit!
     - single repo for all packages
     - one directory per package
     - share package definitions between projects
     - run various build systems
** Pipeline
   - git
   - vendorificator
   - buildbot/jenkins
   - metarake
   - evoker
   - fpm
   - freight
   - apt-get
   - ...
   - profit!
*** git
    - this pipeline really, really depends on git
    - makes heavy use of branching
*** vendorificator
    - "vendor everything"
    - https://github.com/3ofcoins/vendorificator
    - tool to manage vendoring & keeping your dependencies close to
      your code
    - uses git itself - branch per dependency (I think)
    - include packages original sources in the repo
*** CI
*** rake
*** metarake
    - https://github.com/3ofcoins/metarake
    - rake extension which
      - discovers modules and their build targets
      - builds modules with unpublished targets
      - publishes the build targets
    - used to
      - find */Rakefile and *.deb targets
      - build packages not in the apt repo
      - push up to apt repo
*** evoker
    - https://github.com/3ofcoins/evoker
    - download original sources at build time
    - cache them to prevent redownloads
    - (maven/ivy?)
    - Download, patch, preprocess upstream sources without keeping
      them in the repository. Can also cache to avoid repeated long downloads.
      - (what does preprocess mean?)
    - seemingly wholly undocumented :(
*** fpm
    - https://github.com/jordansissel/fpm
    - just use it
    - makes it easy to create
      - deb, rpm, solaris, tar, directory
    - from
      - gem, pypi, pear (php), npm (node), rpm, deb, directory
*** freight
    - "a modern take on the debian archive"
    - https://github.com/rcrowley/freight
    - reprepro
      - once set up, it's nice
      - but it takes a lot of setting up
    - freight solves these problems
*** apt-get
** Questions
   - what approach do you take to versioning? is it automatic?
     - right now, just manual
   - why debian package manager?
     - I work with debian and ubuntu, putting rpm on those wouldn't
       make sense
   - why modify existing packages, when you are using chef? (ie
     install package, then use chef to customize post-install) 
     - I don't want server to start then be configured
     - if I want to run nginx/apache on a different ports, I can't
       without temporary side-effects
       - both start on port 80 as soon as installed
       - [audience] but you can disable the initial start, there's an
         debian policy
       - [audience] think you can also use upstart to disable this behaviour
   - do you do any package signing?
     - freight does this automatically
       - [awesome!]
* Steve O'Grady - What can Java learn from JavaScript?
** A brief history of the past two years
   - FOSDEM '11, "The Rise and Fall and Rise of Java"
     - Rise
       - set top boxes
     - Fall
       - competition
       - late in going open source
       - stagnation/plateau
     - Rise
       - regrowth?
   - FOSDEM '12, "Java in the Age of the JVM"
     - growth of Java.next
       1. overstated
       2. great for Java (the language and the platform)
   - FOSDEM '13?
     - popularity chart, http://redmonk.com/sogrady/2012/09/12/language-rankings-9-12/
       - stack overflow rank / github rank
         - amused to see SuperCollider and Pure Data languages listed :)
       - correlation has been rising over time
         - 0.79 in 2009
         - 0.83 today
       - salient point: java is right up there
     - why are we interested in JavaScript?
       - compared to java
         - lower in search rankings
         - lower in job rankings
       - BUT
         - ohloh rankings for contributions & contributors
           - JS is approaching java
         - ohloh rankings for number of projects:
           - JS has overtaken java here
       - JS is getting substantially more popular
     - why is JS growing?
       - besides the obvious
       - easy wins
       - JSON
         - eg used by mongo
       - analogy: AWS has changed expectations for provisioning speeds
       - Postgres wasn't in a number of linux distros
       - mysql was in every single one
         - easy choice really, even if you prefer postgres
         - relevant to Java
           - how do we get the correct licence so that it can be
             included in a variety of linux distrubutions
     - frameworks matter
       - redmonk top 5
         1. JS (Node.js)
         2. Java
         3. PHP
         4. Python (Django)
         5. Ruby (Rails)
       - Java has curse of choice
         - (Really? Isn't it just Spring or Play? Sure there are
           other players, but there are other players in Ruby world
           too. not massively convinced by this line of reasoning)
         - (His slides listed Noir and Compojure as "java" web frameworks...)
         - 67 java web frameworks on java-source.net
           - many are probably dead projects though
           - what would the equivalent Ruby comparison show?
     - frameworks are evolving
       - embracing asynchronicity
       - node.js
     - going small with microframeworks
       - eg spark for java
* Shane Kerr, BIND10: DNS by cooperating processes
  - BIND 9
    - possibly 80% of DNS servers worldwide
      - (not 80% of queries, or 80% of zones...)
  - BIND 10 is next version
    - Complete redesign, many radical changes
  - ISC
    - Company behind BIND
** History of BIND architecture
   - BIND 8 (May 1997)
     - Monolithic, single-core
     - old-school internet software quality
   - BIND 9 (September 2000)
     - Complete rewrite
     - Monolithic, optional threads
     - Design-by-contract software engineering
     - Solid by standards of day
     - Problems
       - Safe... but brittle
         - Constant consistency checks in code
           - =if (validation_failed) { exit(1); }=
       - "Shared Fate"
         - Modern DNS servers do a lot of stuff
         - on errors, lose all functionality
       - Scalability problems
         - performance flatlines after 4-6 cores
** enter BIND 10
*** Model: Cooperating processes
     - Inspired by Postfix
     - Feels like Erlang too
     - each process does 1 or 2 tasks
     - Service by cooperating processes
       - Answering authoritative DNS queries
       - Transfer DNS zones in/out
       - DHCPv{4,6}
       - etc
     - Only needed processes actually run
*** Process management
     - init process bootstraps
       - message-passing daemon
       - config daemon
       - configured services start
     - if a process dies, it is restarted
       - back-off algorithm to prevent looping
     - on shutdown, everything cleaned up
*** IPC
     - custom message bus
       - nothing met requirements (licence, languages, simplicity,
         works on C++ and python, ...)
       - built on unix-domain sockets
     - security
       - gateway process for administrator auth
       - internally no restrictions
     - separate system to pass open files around
       - needed for zone transfer hand-off
       - also used for privileged socket creation
*** Downsides
     - Complexity
       - complexity at global level
       - hidden (mostly) at lower levels)
       - hidden (partly) from administrators
     - performance overhead
       - existing message bus not very fast
       - no limitations in fast code paths
     - "Weird" for administrators
       - a suspicious, conservative profession ;)
       - look forward to the rants on /. :)
*** status
    - 1.0.0 RC1 out 2013-02-14
    - 1.0.0 hopefully out by 2013-02-28
    - http://bind10.isc.org
* Thibault Koechlin, Naxsi
** Web Application Firewalls
*** Limits of black-list approach
     - variety of technologies
     - Variety of attacks
     - increasing versatility of underlying languages
     - black-list approach is a continuous race
       - (Had already been lost by anti-virus)
*** Positive model
    - closer to the network firewall approach than the anti-virus approach
    - Relies on a very small (~30) set of "core" rules, generally only
      one character at a time
      - simple/double quotes, brackets ...
    - pros
      - very fast
      - resilient to unknown/obfus attacks
      - lack of updates should not lower protections
      - simple rules syntax
    - cons
      - higher false positive rate
      - requires whitelist configuration
*** Rules syntax
=MainRule "str:<" "msg:open tag" "mz:ARGS|URL|BODY|$HEADERS_VAR:Cookie" "s:$XSS:8" id:1302;=
    - One pattern (string or regex)
    - Match zones (where to look for pattern)
    - Score
    - ID (for whitelisting & reporting)
    - As for a real firewall, naxsi rules/whitelists should be as tight as possible:
      - $URL:/foobar|$BODY_VAR:message
    - You are as well able to "factorize" whitelists:
      - $HEADERS_VAR:Cookie
*** Making it as painless as possible
    - User is assisted by python tools
      - whitelist generation from logs or "live" traffic (what do
        these scare quotes mean?)
    - naxsi models makes whitelist reutilization easy (ie whitelists
      set for wordpress)
    - naxsi hugely benefits from nginx/lua/... capabilities:
      - partial learning (based on IP, url, cookie, whatever)
      - partial disable
*** Reporting etc
*** Q&A
    - are you trying to port it to apache?
      - NO
    - will it work with nginx used as a proxy?
      - yes, that's how we mainly use it (with nginx as a reverse proxy)
    - graphing tools - are they part of naxsi?
      - yes it comes with all of the reporting tools
    - can you use it for shared hosting?
      - use it in learning mode, then make it more of an IDS
* Charles Nutter, Invokedynamic: tales from the trenches
Warning: I was late for this talk, it was very fast, and most of it
went over my head. The initial notes were just "things too google
later"; much was filled in afterwards through researching various keywords.
  - LambdaForm
  - MethodHandle and invokedynamic
    - http://blog.headius.com/2008/09/first-taste-of-invokedynamic.html
      - problem: want to invoke methods without having a method
        signature statically defined in bytecode (which
        invokevirtual requires..?)
      - traditional solution: a Method object from java reflection api
        - one problem: reflected invocation is sloooow
          - runtime checks
          - boxing primitives into Objects, boxing args into arrays
      - old JRuby way: create an invoker class for each core class method
        - eg for String#split, we create a class with a shim method
          with bytecode which:
          - casts to RubyString
          - calls invokevirtual on RubyString/split
        - feels quite wasteful to have hundreds of these classes
        - worse: it's going into PermGen space, which is at a premium
      - AnonymousClassLoader: garbage-collectible classes
        - To make these mini-classes GCable, they need to have their
          own ClassLoader
        - Generated classes can share structure with existing classes
          rather than creating everything anew
          - "like class X but with different constant pool"
          - meaning we can generate shim bytecode *once* and repurpose
            it for different ruby methods
        - but: doesn't fix boxing issue; either you have one method
          =Object call(Object[] args);= and pay the boxing penalty, or
          you have an explosion of method signatures, one for each
          number of arguments (and an even bigger combinatorial
          explosion if you also want to avoid boxing primitives)
          - cf
            https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/IFn.java
      - MethodHandle: primitive reference to a method
        - created either:
          - from reflection Method object
          - from MethodHandles factory
        - adaptation operations:
          - currying: MethodHandle + arg1 => MethodHandle
            - cf currying in Haskell/ML/etc
      - InvokeDynamic, JSR-292
        - opcode to invoke calls dynamically
          - but still want JVM to optimize callsite in the same way
        - causes Hotspot to treat invokeinterface calls on a special
          "Dynamic" class as "special"
        - use Linkage.registerBootstrapMethod to register a
          "bootstrap method" which determines which method will be
          called at this callsite
          - will be saved and used on subsequent calls, so bootstrap
            method doesn't get re-evaluated
        - Note this is as at 2008. Not final implementation
  - https://github.com/headius/invokebinder
  - RubyFlux, a ruby to java complier
    - https://github.com/headius/rubyflux
    - basic principle: create one giant interface RObject which has
      every single method defined in the program
    - each object implements RObject and only defines the methods it
      cares about
* Paul Sandoz, OpenJDK Lambda the Ultimate
  - http://earthly-powers.blogspot.co.uk/
  - Why OpenJDK lambda?
    - About bloody time!
    - "Excessive use of Guava's functional programming idioms can lead
      to verbose, confusing, unreadable, and inefficient code. These are
      by far the most easily (and most commonly) abused parts of Guava,
      and when you go to preposterous lengths to make your code "a
      one-liner," the Guava team weeps."
      - from http://code.google.com/p/guava-libraries/wiki/FunctionalExplained
    - Allow programming patterns that require modeling code as data to be
      convenient and idiomatic in Java
    - lift the level of abstraction in libraries when manipulating data
      - sequential and parallel programming
  - Can download builds of OpenJDK lambda now, and give them feedback
  - Modifying the language
    - =(String s) -> s.toLowerCase()=
      - untyped! without context, doesn't make sense
    - Targeting to functional interface type:
      - =Function<String,String> f = (String s) -> s.toLowerCase();=
    - Improved inference
      - =Function<String,String> f = s -> s.toLowerCase();=
    - Method references
      - =Function<String,String> f = String::toLowerCase;=
  - Interface evolution of default methods
  - Common functional interfaces =java.util.function=
  - Bulk operations on collections
  - Explicit but unobtrusive parallelism
    - bleah, parallel collections :/
  - Big picture: Java is changing at all levels
    - libraries: fork/join
    - language & compiler: type inference engine
    - VM: invokedynamic
  - Talk recommendation:
    - Guy Steele, How to think about parallel programming: Not!
      - infoQ link
  - Demo
    - lambdas don't create classes... how?
    - invokedynamic calls for lambda expressions
    - LambdaMetaFactory
      http://download.java.net/jdk8/docs/api/java/lang/invoke/LambdaMetafactory.html
    - Particularly impressed with the method handles
      - =Callable<Properties> = System::getProperties;=
      - =IntFunction<String[]> newStringArray = String[]new;= arrays too!
  - Streams API
    - fluent interface
      - ref, int, long, double variants
    - raises abstraction for parallel operations on data
      - conceptual and syntactic gap between sequential and parallel reduced
      - inverts control of data traversal
    - integrated into existing collection framework
      - using default methods
    - lazy evaluation
      - with a =.collect()= to finally force evaluation
    - two ways to go parallel
      - divide and conquer; merge intermediate results
        - =toArray()= has an optimization:
          - if output array size == input array size, don't bother
            with the divide and recombine
      - concurrently stuff things into a concurrent data structure
      - Demo: comparison of parallel foreach and parallel collect
        - foreach put things into synchronized list
          - ordering not guaranteed
        - collect joins lists together at end
          - ordering guaranteed
    - not entirely free lunch (shock horror)
      - identity and associativity are important to give library
        optimization capability
    - new traversable data structure
      - a parallel analogue to Iterator
      - =java.util.Spliterable=
  - cheeky microbenchmarking
    - looks faster
    - health warning
    - http://code.google.com/p/caliper/
  - Demo based on @cgrand's clojure game of life example
  - CountedCompleter
    - http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/CountedCompleter.html
* Ben Evens, Martijn Verburg, Adopt OpenJDK. What we've learned, where we're going
  - The London Java Community guys
  - Adopt OpenJDK is...
    - A JUG led initiative to improve OpenJDK participation
    - A programme to help improve OpenJDK workflow
    - An advocacy programme
    - A feeder programme of ideas and talent
    - A mentoring and educational incubator
    - A place to prorotype new social/community workflow ideas
    - Early feedback mechanism
    - An area to try some small technical ideas
    - An area to work with casual as well as full-time participants
    - Ideas and tech will shift to the OpenJDK on *merit*
      - usual OpenJDK rules apply
    - example: worked with Tom Christiansen (of Perl fame) to help him
      get some Unicode regex fixes in that he'd been sitting on
      - but his lack of familiarity with codebase/community/process
        whatever might otherwise have prevented this
  - OpenJDK code quality is *variable*
    - some is quite old and "sturdy"
  - Huge developer demand to get involved
    - OpenJDK hack days sell out in hours
    - ~10 hack days in 2012
    - In 2-3 hours, 20-30 developers can get started on OpenJDK
      - This propagates
  - Developers are scared of OpenJDK
    - They think only Rocket Scientists need apply
      - Charles Nutter doesn't help with his invokedynamic talks ;)
      - They think you need advanced C/C++/Assembler skills
    - They are scared to make public contributions
    - They are scared they will break something
  - Devs are surprised at the helpfulness
    - OpenJDK has somewhat of a surly reputation
      - main contributors are very busy
    - Most OpenJDK projects have a very welcoming attitude
  - Devs can't build OpenJDK easily
    - Even with =build-infra= it's a barrier to entry
    - Lack of IDE support - no IntelliJ, Eclipse, NetBeans
      - got to use emacs or vi or whatever
    - =make= is an unfamiliar build tool for many
    - Developers guide is out of date
    - even with =jtreg= improvements - it's a barrier to entry
      - TestNG support is very welcome
    - Lack of access to complete (open) tests
      - one issue here is that some tests may be based on customer
        data -- can't be released without anonymizing first
    - Lack of alternative test platforms
    - Lack of CI
  - Developers want to code socially
    - They are used to
      - Github etc
      - collaborative coe review
      - to open issue trackers
      - to UI/UX which leads them to information
      - ideas/designs being discussed more fully
        - JEP system while seemingly fair is causing frustration
          - "casual" contributors don't get same voice
          - difficult in tchrist example above
      - consistent technical standards
        - OpenJDK projects each have their own
  - Developers struggle to submit code
    - Many branches/forests/trees confuse them
      - so many projects, which one is the one I want to commit to?
    - =webrev= is a major hurdle
      - patch turnaround times are slow for external contributors
  - Developers love the idea of OpenJDK
    - we're promoting the hell out of it
    - 4 dedicated LJC advocates
    - Brazil-wide programme launched by SouJava
  - Hackdays are the best way to educate
    - 20+ hackdays planned globally in 2013
    - All major conferences to hold them
      - arranged via the JUG leaders and Java Champions programme
    - Hackday materials to be shared on GitHub
    - LJC advocates working on Chef/vagrant builds
      - We love Devops people :)
  - Testing!
    - Testfest planned with IBM and Oracle et al
      - TestNG tests to be written
    - Agreement to open up tests
      - Oracle, IBM, RedHat, Azul et al
    - Initial discussions around a secure distributed build farm
      - cloudbees willing to donate compute time/space
* Heather VanCura and Martijn Verburg, Java Community Process, state of the community
  - JCP is 14 years old
    - 350 JSRs submitted over the years
      - Java Specification Request
    - currently 29 active JSRs
  - 80+ different members have led JSRs
  - eg JSR335 Lambda Expressions
  -
* spontaneous graph processing talk
  - Introduction to graphs
  - Implementation strategies
    - RDF seems promising: triple corresponds to Vertex->Edge->Vertex
    - BUT what about things changing over time? (Example: Gerhard
      Schröder and his 6 wives)
    - Time
* Teun de Lange, Jazzsperiments
  - Talk blurb: https://fosdem.org/2013/schedule/event/jazzperiments/
  - looks like it was recorded
  - experiment
    - clarinet -> microphone -> processing -> bassline
    - bass on a bit of a delay
    - but lots of intelligence too
    - Java Sound Engine
  - problems
    - processing latency causes noticable delay
    - solution: use metronome and delay by fixed number of beats
      - plays in sync, but a bit late
  - other ideas
    - sampling and playback
  - some impressive visualizations
    - live creation of musical score
    - John cage style notation
  - Q&A
    - what do you do about java GC?
      - minimize object churn, etc
    - have you done experiments with predictive algorithms
      - 
    - have you done anything with progressions?
      - I've got a way to tell it the key, and to change chord after 4
        bars. you have to get used to it though.
* Leslie Hawthorn, the keeper of secrets
  - example: contributor on critical path going through tough time
    - less able to contribute than before
    - doesn't want to talk about why
    - others see it as deliberate discourtesy
    - resolution: try to encourage disclosure
      - (really? some things are truly private)
      - (perhaps disclose that *something* is wrong without disclosing *what*?)
  - example: person who doesn't get it
    - cheerleader
    - advocate
    - their actions harm the flow of the project
    - other people get cranky if they're spending time herding errant
      fellow volunteers
      - they'll complain to each other, but won't take their concerns
        directly to the problem individual
  - handling these situations quickly and effectively is messy,
    uncomfortable and incredibly necessary
  - Techniques
    - try to direct people towards their strengths
      - eg get the person who "doesn't get it" to do marketing rather
        than technical work
    - model: conversations depend on two dimensions
      1. strength of relationship
      2. alignment of interests
    - talking with people we like and agree with is easy
    - everything else feels like it's going to be really painful
      - ie good relationship, but poor alignment of interests, or vice versa
    - be willing to ask for what you want
    - ask the other party what they need
    - find common ground
    - reach agreement
    - this means "Radical honesty" (!= being a tactless jerk)
    - being diplomatic != being disingenuous
    - do you want to be right or do you want to win?
* Notes from conversation with Eric Sorenson and Nathen Harvey
  - testing configuration
    - you can't get absolute certainty about your catalog without
      running it on a real server
    - but you want to avoid testing puppet and focus on testing your
      actual code
      - cf ruby projects which end up testing ActiveSupport
    - In sw dev community, this is (largely) a solved issue. Key points:
      - push exhaustive testing down to unit level
      - layering of integration tests; integrate only as much of the
        system as you need to run your tests
        - in-process testing is the hot new thing here -- don't create
          a webserver to serve your site, just call the toplevel
          methods to simulate web requests
          - specifications such as servlets, rack, wsgi *really* help
            with this
        - inproctester is a tool for this
      - use as little testing as possible with your whole app on the
        full stack; ideally just one test that checks everything is
        connected together
      - Must always keep in mind the tradeoff between time test takes
        and value it provides
      - http://dan.bodar.com/2012/02/28/crazy-fast-build-times-or-when-10-seconds-starts-to-make-you-nervous/
  - testing puppet specifically
    - rspec-puppet a little rough round the edges for a unit testing framework
      - when you instantiate something, you instantiate the whole
        graph below it
        - example where adding 2 tests increased test time by ~15 seconds
        - this is painful for unit tests
      - dependency testing is tied to implementation
        - if you test for presence of a =require => Package[foo]= on =File[bar]=, you
          won't see =package {'foo': before => File[bar]}=
        - worse, there seems to be *no way* to test for dependencies
          of the form =Package[foo] -> File[bar]=
        - https://github.com/rodjek/rspec-puppet/issues/31
  - If I wanted to write a new frontend language for puppet, where
    would I "cut in"?
    - Generate a catalog; it's the type that goes over the wire to the
      agent.
    - puppetlabs themselves have no plans to do this; however they are
      interested in introducing middleware here
      - eg a caching proxy, which only recalculates when facts change
        - one fact is unix time though, which is always changing
  - facter: the rough edges
    - =memorysize= is unfriendly for scripting
      - we had a use case where we wanted varnish to use at most 75%
        of physical memory
      - ended up writing a custom fact for this
    - unix time -- is it needed?
    - seems to be quite a bit of cruft
  - How do you folks manage certificate generation and signing?
    - We use =puppet cert= and let puppet autogenerate the key on
      first run
    - We have scripted our provisioner to ssh to the puppetmaster and
      sign the cert when provisioning a new machine
  - Chef servers are not compute-bound
    - delegate most of the computation to the agents
    - push the cookbooks out
    - how do you manage secrets? (db passwords etc)
      - facility for encrypting secrets
        - if you use chef bootstrap, chef will autogenerate keys for you
        - all done with TLS
  - Eric's recent puppetcamp talk on puppet, present and future:
    http://www.slideshare.net/ahpook1/puppet-3-present-and-future-tense
