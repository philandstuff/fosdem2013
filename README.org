#+TITLE:FOSDEM 2013

* Nathan Harvey, Learning to Automate
** evolving towards automation:
   1. just make it work
   2. then write notes and store in server.txt
   3. then publish those notes in wiki
   4. then convert notes to scripts
   5. then put scripts into source control
      - and not the =.bak= or =.<date>= kind
** new experiences when automating:
   - new terminology
   - new programming languages
   - new way of thinking about infrastructure
     - livestock, not pets
** challenges for educators
   - snowflakes -- everyone's infrastructure is different and under
     different constraints
   - deployment variation
     - loads and loads of options here
     - OS packages
     - .jars and .wars
     - capistrano
     - not to mention options for injecting environment-specific config
   - massively varying background of practitioners
     - sysadmins vs devs, broadly
     - but variation within and outside of these categories
   - rate of innovation of field
** Three archetypal learners
   - senior sysadmin
     - understands:
       - domain
       - tooling
     - doesn't understand
       - high-level abstraction
       - testing and TDD
     - needs examples and peer-based learning
   - "Trust fund" kid
     - has inherited an existing chef/puppet/cfengine codebase but
       doesn't understand it
     - value of automation lowered by lack of understanding
     - needs mentoring
   - the dev migrating to operations
     - understands:
       - abstraction
       - testing
     - doesn't understand:
       - OS-level concepts and techniques
     - willing to dig into ruby source code to understand things
     - needs domain expertise
   - Pattern here: massive variation in:
     - motivation
     - existing skills
** How can we help?
   - Community
     - conferences, usergroups, etc
   - support and mentoring for those around you
** finally: if you're using vagrant, use veewee!
* Brian Berry, Using Ruby testing frameworks for sanity
  - code at https://github.com/bryanwb/tk-demo
** standard shape:
   - appservers, loadbalancers, database nodes, database caches
** big data deathstar is coming
   - hadoop, zookeeper, apache mesos
** testing; two kinds
   - white box
   - black box
** you should use ruby
   - lightweight
   - libraries
   - rspec
   - easy to mock services (sinatra) (what does this mean?)
   - vagrant!
** minitest chef handler
** test kitchen
** Jamie CI aka Test-Kitchen 1.0
   - simple job:
     - define machines
     - provide virtualization backend
       - eg vagrant
   - define VMs using a single yaml file
   - supports librarian-chef and berkshelf
   - tests VMs concurrently
** BATS - Bash Automated Testing System
   - testing using bash, sort of
** "Smoke" tests
   - Don't need to test multiple OS versions
   - How to DRY up common driver configs?
   - Where to put IP config?
** logging
   - test-kitchen creates one log per VM
** wiring
   - hardcoding IP address in Vagrantfile?
   - assigning IP using Chef Server or Puppetmaster?
   - Presenting: Chef-Workflow
** Brian's super-cool Systems Management model
   - Finite State Machine (zookeeper) [wtf?]
   - orchestration (rake)
   - discovery (puppetdb/chef server)
   - provisioning (puppet/chef/cfengine)
   - machines (test-kitchen)
   - virt. drivers (vagrant)
** More awesome ruby libraries
   - Faraday
   - Sinatra
   - Rspec-dns
   - ruby-dns
** Summary
   - You can do a lot of basic integration testing _right now_ with
     vagrant + rake
   - concurrent VM task execution important (though controversial)
   - Need DSL for integration tests
   - Test-Kitchen alpha but exciting
   - There is gold in Chef-Workflow
   - We need public CI for chef cookbooks etc
** zookeeper
   - useful for maintaining dynamic state
   - master/slave
   - group membership
   - when I add an appserver, I don't want to wait for the next puppet
     run to have it added to the lb pool
     - zookeeper "basically" a key-value store with events and notifications
     - load balancer can listen for new appservers
** TODO Aside: Brians emacs for ruby:
   - Paredit?!
   - RBlock?
   - Ruby mode
* Pat Debois, spontaneous veewee talk
** vagrant
   - creates and destroys VMs very quickly
   - all starts from a base box
** veewee
   - https://github.com/jedi4ever/veewee
   - takes pain out of building vagrant boxes
     - also KVM, vmware
   - interact with those vms (up/destroy/halt/ssh)
   - export them: OVA for fusion, IMG for KVM, ovf for virtualbox
* Maciej Pasternacki, A Continuous Packaging Pipeline
  - @mpasternacki
  - http://bit.ly/cont-pkg < talk notes
** Web infrastructure problems
   - nginx is too old
   - I need node.js
     - compiling on the server is /wrong/
   - I need foo.jar on all appservers
     - a Java VM would help using it
** Package all the things!
   - http://xallthey.com/package.all.the.things
   - barriers:
     - debian policy manual
   - Goals:
     - 
       1. git push
       2. ...
       3. profit!
     - single repo for all packages
     - one directory per package
     - share package definitions between projects
     - run various build systems
** Pipeline
   - git
   - vendorificator
   - buildbot/jenkins
   - metarake
   - evoker
   - fpm
   - freight
   - apt-get
   - ...
   - profit!
*** git
    - this pipeline really, really depends on git
    - makes heavy use of branching
*** vendorificator
    - "vendor everything"
    - https://github.com/3ofcoins/vendorificator
    - tool to manage vendoring & keeping your dependencies close to
      your code
    - uses git itself - branch per dependency (I think)
    - include packages original sources in the repo
*** CI
*** rake
*** metarake
    - https://github.com/3ofcoins/metarake
    - rake extension which
      - discovers modules and their build targets
      - builds modules with unpublished targets
      - publishes the build targets
    - used to
      - find */Rakefile and *.deb targets
      - build packages not in the apt repo
      - push up to apt repo
*** evoker
    - https://github.com/3ofcoins/evoker
    - download original sources at build time
    - cache them to prevent redownloads
    - (maven/ivy?)
    - Download, patch, preprocess upstream sources without keeping
      them in the repository. Can also cache to avoid repeated long downloads.
      - (what does preprocess mean?)
    - seemingly wholly undocumented :(
*** fpm
    - https://github.com/jordansissel/fpm
    - just use it
    - makes it easy to create
      - deb, rpm, solaris, tar, directory
    - from
      - gem, pypi, pear (php), npm (node), rpm, deb, directory
*** freight
    - "a modern take on the debian archive"
    - https://github.com/rcrowley/freight
    - reprepro
      - once set up, it's nice
      - but it takes a lot of setting up
    - freight solves these problems
*** apt-get
** Questions
   - what approach do you take to versioning? is it automatic?
     - right now, just manual
   - why debian package manager?
     - I work with debian and ubuntu, putting rpm on those wouldn't
       make sense
   - why modify existing packages, when you are using chef? (ie
     install package, then use chef to customize post-install) 
     - I don't want server to start then be configured
     - if I want to run nginx/apache on a different ports, I can't
       without temporary side-effects
       - both start on port 80 as soon as installed
       - [audience] but you can disable the initial start, there's an
         debian policy
       - [audience] think you can also use upstart to disable this behaviour
   - do you do any package signing?
     - freight does this automatically
       - [awesome!]
* Steve O'Grady - What can Java learn from JavaScript?
** A brief history of the past two years
   - FOSDEM '11, "The Rise and Fall and Rise of Java"
     - Rise
       - set top boxes
     - Fall
       - competition
       - late in going open source
       - stagnation/plateau
     - Rise
       - regrowth?
   - FOSDEM '12, "Java in the Age of the JVM"
     - growth of Java.next
       1. overstated
       2. great for Java (the language and the platform)
   - FOSDEM '13?
     - popularity chart, http://redmonk.com/sogrady/2012/09/12/language-rankings-9-12/
       - stack overflow rank / github rank
         - amused to see SuperCollider and Pure Data languages listed :)
       - correlation has been rising over time
         - 0.79 in 2009
         - 0.83 today
       - salient point: java is right up there
     - why are we interested in JavaScript?
       - compared to java
         - lower in search rankings
         - lower in job rankings
       - BUT
         - ohloh rankings for contributions & contributors
           - JS is approaching java
         - ohloh rankings for number of projects:
           - JS has overtaken java here
       - JS is getting substantially more popular
     - why is JS growing?
       - besides the obvious
       - easy wins
       - JSON
         - eg used by mongo
       - analogy: AWS has changed expectations for provisioning speeds
       - Postgres wasn't in a number of linux distros
       - mysql was in every single one
         - easy choice really, even if you prefer postgres
         - relevant to Java
           - how do we get the correct licence so that it can be
             included in a variety of linux distrubutions
     - frameworks matter
       - redmonk top 5
         1. JS (Node.js)
         2. Java
         3. PHP
         4. Python (Django)
         5. Ruby (Rails)
       - Java has curse of choice
         - (Really? Isn't it just Spring or Play? Sure there are
           other players, but there are other players in Ruby world
           too. not massively convinced by this line of reasoning)
         - (His slides listed Noir and Compojure as "java" web frameworks...)
         - 67 java web frameworks on java-source.net
           - many are probably dead projects though
           - what would the equivalent Ruby comparison show?
     - frameworks are evolving
       - embracing asynchronicity
       - node.js
     - going small with microframeworks
       - eg spark for java
* Shane Kerr, BIND10: DNS by cooperating processes
  - BIND 9
    - possibly 80% of DNS servers worldwide
      - (not 80% of queries, or 80% of zones...)
  - BIND 10 is next version
    - Complete redesign, many radical changes
  - ISC
    - Company behind BIND
** History of BIND architecture
   - BIND 8 (May 1997)
     - Monolithic, single-core
     - old-school internet software quality
   - BIND 9 (September 2000)
     - Complete rewrite
     - Monolithic, optional threads
     - Design-by-contract software engineering
     - Solid by standards of day
     - Problems
       - Safe... but brittle
         - Constant consistency checks in code
           - =if (validation_failed) { exit(1); }=
       - "Shared Fate"
         - Modern DNS servers do a lot of stuff
         - on errors, lose all functionality
       - Scalability problems
         - performance flatlines after 4-6 cores
** enter BIND 10
*** Model: Cooperating processes
     - Inspired by Postfix
     - Feels like Erlang too
     - each process does 1 or 2 tasks
     - Service by cooperating processes
       - Answering authoritative DNS queries
       - Transfer DNS zones in/out
       - DHCPv{4,6}
       - etc
     - Only needed processes actually run
*** Process management
     - init process bootstraps
       - message-passing daemon
       - config daemon
       - configured services start
     - if a process dies, it is restarted
       - back-off algorithm to prevent looping
     - on shutdown, everything cleaned up
*** IPC
     - custom message bus
       - nothing met requirements (licence, languages, simplicity,
         works on C++ and python, ...)
       - built on unix-domain sockets
     - security
       - gateway process for administrator auth
       - internally no restrictions
     - separate system to pass open files around
       - needed for zone transfer hand-off
       - also used for privileged socket creation
*** Downsides
     - Complexity
       - complexity at global level
       - hidden (mostly) at lower levels)
       - hidden (partly) from administrators
     - performance overhead
       - existing message bus not very fast
       - no limitations in fast code paths
     - "Weird" for administrators
       - a suspicious, conservative profession ;)
       - look forward to the rants on /. :)
*** status
    - 1.0.0 RC1 out 2013-02-14
    - 1.0.0 hopefully out by 2013-02-28
    - http://bind10.isc.org
* Thibault Koechlin, Naxsi
** Web Application Firewalls
*** Limits of black-list approach
     - variety of technologies
     - Variety of attacks
     - increasing versatility of underlying languages
     - black-list approach is a continuous race
       - (Had already been lost by anti-virus)
*** Positive model
    - closer to the network firewall approach than the anti-virus approach
    - Relies on a very small (~30) set of "core" rules, generally only
      one character at a time
      - simple/double quotes, brackets ...
    - pros
      - very fast
      - resilient to unknown/obfus attacks
      - lack of updates should not lower protections
      - simple rules syntax
    - cons
      - higher false positive rate
      - requires whitelist configuration
*** Rules syntax
=MainRule "str:<" "msg:open tag" "mz:ARGS|URL|BODY|$HEADERS_VAR:Cookie" "s:$XSS:8" id:1302;=
    - One pattern (string or regex)
    - Match zones (where to look for pattern)
    - Score
    - ID (for whitelisting & reporting)
    - As for a real firewall, naxsi rules/whitelists should be as tight as possible:
      - $URL:/foobar|$BODY_VAR:message
    - You are as well able to "factorize" whitelists:
      - $HEADERS_VAR:Cookie
*** Making it as painless as possible
    - User is assisted by python tools
      - whitelist generation from logs or "live" traffic (what do
        these scare quotes mean?)
    - naxsi models makes whitelist reutilization easy (ie whitelists
      set for wordpress)
    - naxsi hugely benefits from nginx/lua/... capabilities:
      - partial learning (based on IP, url, cookie, whatever)
      - partial disable
*** Reporting etc
